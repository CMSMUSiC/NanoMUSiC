#!/usr/bin/env python3

from enum import Enum
from typing import Optional, Union
from analysis_builder import ProcessingSite
from distribution_model import DistributionType
from rich import console
from typing_extensions import Annotated
import typer
import metadata
from metadata import ClassType, Years
import sys
import os
import time
import subprocess
from functools import wraps


def exec_command(cmd: str) -> None:
    try:
        subprocess.run(
            cmd,
            check=True,  # Raises CalledProcessError on non-zero exit
            shell=True,
            stdout=subprocess.PIPE,  # Capture standard output
            stderr=subprocess.PIPE,  # Capture standard error
        )
    except subprocess.CalledProcessError as e:
        print(f"Error during execution: {e}")
        print(f"Standard Output: {e.stdout.decode()}")
        print(f"Standard Error: {e.stderr.decode()}")
        sys.exit(-1)


def execution_time(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        elapsed_time = end_time - start_time
        formatted_time = time.strftime("%H:%M:%S", time.gmtime(elapsed_time))
        print(f"Execution time of {func.__name__}: {formatted_time}")
        return result

    return wrapper


############################################################################
############################################################################
# Classification
############################################################################
############################################################################
classification_app = typer.Typer(
    help="Launch and control the Classification steps. Expected workflow: parse -> build -> preprocess -> btag-efficiency -> launch -> merge -> unwrap -> fold -> make-distributions. Each step depends on the previous one.",
    pretty_exceptions_show_locals=False,
)


@classification_app.command()
@execution_time
def parse(
    samples_list: Annotated[
        str, typer.Argument(help="File with DAS names of all samples (one per line).")
    ] = "samples.txt",
):
    """
    Will parse the list of DAS names and format it in the MUSiC format, including x-sections.
    """
    import parse_sample_list

    parse_sample_list.parse(samples_list)


@classification_app.command()
@execution_time
def build(
    config_file: Annotated[
        str,
        typer.Argument(
            help="parsed_sample_list.toml file path, as build by the parser."
        ),
    ] = "parsed_sample_list.toml",
    processing_site: Annotated[
        ProcessingSite, typer.Option(help="Region or institute where processing files.")
    ] = ProcessingSite.RWTH,
):
    """
    Will query all files LFN, for each sample and add it to the analysis_config.toml.
    """
    from analysis_builder import build_analysis_config

    build_analysis_config(config_file, processing_site)


@classification_app.command()
@execution_time
def preprocess(
    config_file: Annotated[
        str,
        typer.Argument(help="analysis_config.toml file path, as provided by builder."),
    ] = "analysis_config.toml",
):
    """
    Will scan all MC input files and collect the total MC weight per sample.
    """
    import preprocessing

    preprocessing.preamble()

    print("Computing sum_weights ... ")
    preprocessing.compute_sum_weights(config_file)


@classification_app.command()
@execution_time
def btag_efficiency(
    config_file: Annotated[
        str,
        typer.Argument(help="analysis_config.toml file path, as provided by builder."),
    ] = "analysis_config.toml",
):
    """
    Will scan all MC input files and compute the btag_efficiency_map.
    """
    import btag_efficiency

    btag_efficiency.preamble()

    print("Computing btag_efficiency_map ... ")
    btag_efficiency.compute_btag_efficiency(config_file)
    btag_efficiency.merge_btag_efficiency_maps()
    btag_efficiency.make_teffs()


class ClassificationTarget(str, Enum):
    Condor = "condor"
    Dev = "dev"
    Parallel = "parallel"


@classification_app.command()
@execution_time
def launch(
    config_file: Annotated[
        str,
        typer.Argument(help="analysis_config.toml file path"),
    ] = "analysis_config.toml",
    description: Annotated[
        Union[str, None],
        typer.Argument(
            help="description file path of the classification being launched"
        ),
    ] = None,
    target: ClassificationTarget = ClassificationTarget.Parallel,
    process: Union[str, None] = None,
    year: Union[metadata.Years, None] = None,
    max_files: int = sys.maxsize,
    split_size: int = 1,
    dry_run: bool = False,
    num_cpus: int = 128,
):
    """
    Launch the classification jobs for a given target.
    """

    # Read the file content and remove whitespace characters
    def normalize_content(file_path):
        with open(file_path, "r") as file:
            content = file.read()
            normalized_content = "".join(content.split())
        return normalized_content

    if not description:
        description_template_file = (
            "{}/NanoMUSiC/Classification/assets/description_template.txt".format(
                os.getenv("MUSIC_BASE")
            )
        )

        os.system("cp {} description.txt".format(description_template_file))
        os.system("/usr/bin/vim +normal\\ G description.txt")

        if normalize_content(description_template_file) == normalize_content(
            "description.txt"
        ):
            print(
                "ERROR: Could not set description. Description should not be empty.",
                file=sys.stderr,
            )
            sys.exit(-1)
    else:
        if description.endswith(".txt"):
            if os.path.isfile(description):
                proc = subprocess.run(
                    "cp {} description.txt".format(description),
                    shell=True,
                    capture_output=True,
                    text=True,
                )
                if proc.returncode != 0:
                    print(
                        "ERROR: Could not copy description file.\n{}\n{}".format(
                            proc.stdout, proc.stderr
                        ),
                        file=sys.stderr,
                    )
                    sys.exit(-1)
            else:
                print(
                    "ERROR: Could not set description. File ({}) not found.".format(
                        description
                    ),
                    file=sys.stderr,
                )
                sys.exit(-1)

        else:
            print(
                "ERROR: Could not copy description file. Description file should end with .txt",
                file=sys.stderr,
            )
            sys.exit(-1)

    import classification

    if not os.path.exists("sum_weights.json"):
        print(
            "ERROR: Could not find sum_weights.json. Did you run the preprocess?",
            file=sys.stderr,
        )
        sys.exit(-1)

    if not os.path.exists("btag_eff_maps"):
        print(
            'ERROR: Could not find btag_eff_maps. Run "btag-efficiency" before "launch".',
            file=sys.stderr,
        )
        sys.exit(-1)

    match target:
        case ClassificationTarget.Dev:
            classification.launch_dev(config_file, process, year, max_files)
        case ClassificationTarget.Parallel:
            classification.launch_parallel(
                config_file, process, year, max_files, 1, num_cpus
            )
        case _:
            print("ERROR: Invalide Classification target {}", target, file=sys.stderr)
            sys.exit(-1)


@classification_app.command()
@execution_time
def merge(
    config_file: Annotated[
        str,
        typer.Argument(help="analysis_config.toml file path"),
    ] = "analysis_config.toml",
    inputs_dir: str = "classification_outputs",
    num_cpus: int = 124,
):
    """
    Merge classification results.
    """
    import classification

    classification.merge_classification_outputs(
        config_file_path=config_file,
        inputs_dir=inputs_dir,
        num_cpus=num_cpus,
    )


@classification_app.command()
@execution_time
def unwrap(
    config_file: Annotated[
        str,
        typer.Argument(help="analysis_config.toml file path"),
    ] = "analysis_config.toml",
    inputs_dir: str = "classification_merged_results",
    validation_inputs_dir: str = "validation_merged_results",
    num_cpus: int = 128,
):
    """
    Will serialize to ROOT (TH1F) all recorded EventClasses.
    """
    import classification

    classification.serialize_to_root(
        config_file, inputs_dir, validation_inputs_dir, num_cpus
    )


@classification_app.command()
@execution_time
def fold(
    inputs_dir: str = "classification_root_files",
    validation_inputs_dir: str = "validation_root_files",
):
    """
    Will merge related histograms (TH1F) into one ROOT file per event class.
    """
    import classification

    classification.fold(
        inputs_dir,
        validation_inputs_dir,
    )


class FoldAndPlotTarget(str, Enum):
    Classification = "classification"
    Validation = "validation"
    All = "all"


@classification_app.command()
@execution_time
def make_distributions(
    inputs_dir: str = "classification_folded_files",
    validation_inputs_dir: str = "validation_folded_files",
    name_filter: str = "*",
    skip_per_year: bool = True,
    target: FoldAndPlotTarget = FoldAndPlotTarget.All,
):
    """
    Will merge related histograms (TH1F) into Distributions (usefull data format for plotting and scan).
    """
    import classification

    if target == FoldAndPlotTarget.Classification or target == FoldAndPlotTarget.All:
        classification.make_distributions(
            inputs_dir,
            validation_inputs_dir,
            name_filter,
            None,
            skip_per_year,
        )
    # if target == FoldAndPlotTarget.Validation or target == FoldAndPlotTarget.All:
    #     classification.make_distributions(
    #         inputs_dir,
    #         validation_inputs_dir,
    #         None,
    #         "*" if target == FoldAndPlotTarget.All else name_filter,
    #         skip_per_year,
    #     )


############################################################################
############################################################################
# Plotter
############################################################################
############################################################################
plot_app = typer.Typer(
    help="Produce different MUSiC plots.", pretty_exceptions_show_locals=False
)


@plot_app.command()
@execution_time
def distribution(
    input_dir: str = "classification_distributions",
    output_dir: str = "classification_plots",
    scan_summary_dir: str = "scan_summary_plots",
    filters: list[str] = ["*"],
    num_cpus: int = 128,
):
    """
    Produce plots all distribution, matching (glob matching) the different filters.
    """
    from plotter import plotter

    plotter(input_dir, scan_summary_dir, filters, output_dir, num_cpus)


@plot_app.command()
@execution_time
def validation(
    input_dir: str = "validation_distributions",
    output_dir: str = "validation_plots",
    filters: list[str] = ["*"],
    num_cpus: int = 128,
):
    """
    Produce plots all validation, matching (glob matching) the different filters.
    """
    from plotter import plotter

    plotter(input_dir, "foo", filters, output_dir, num_cpus, True)


class YearsToPlot(str, Enum):
    Run2016 = "2016"
    Run2017 = "2017"
    Run2018 = "2018"
    Run2 = "Run2"
    All = "all"


@plot_app.command()
@execution_time
def most_occupied(
    input_file: str = "classification_plots/integral_pvalues_data.json",
    output_dir: str = "classification_most_occupied",
    skip_per_year: bool = True,
):
    """
    Plot the occupancy and p_integral of most occupied classes.
    """
    from concurrent.futures import ProcessPoolExecutor, as_completed
    from rich.progress import track
    from rich.console import Console

    from integral_pvalues import integral_pvalues_summary

    os.system("rm -rf {}".format(output_dir))
    os.system("mkdir -p {}".format(output_dir))

    years = ["2016", "2017", "2018", "Run2"]
    if skip_per_year:
        years = ["Run2"]

    with ProcessPoolExecutor(max_workers=12) as executor:
        futures = []
        for y in years:
            futures.append(
                executor.submit(
                    integral_pvalues_summary,
                    input_file,
                    output_dir,
                    y,
                    20,
                    True,
                    True,
                    True,
                )
            )
            futures.append(
                executor.submit(
                    integral_pvalues_summary,
                    input_file,
                    output_dir,
                    y,
                    40,
                    True,
                    True,
                    True,
                )
            )
            futures.append(
                executor.submit(
                    integral_pvalues_summary,
                    input_file,
                    output_dir,
                    y,
                    100,
                    True,
                    True,
                    True,
                )
            )

        console = Console()
        for future in track(
            as_completed(futures),
            total=len(futures),
            description="Most occupied scenarios...",
            console=console,
        ):
            year, num_classes = future.result()
            console.print(f"Done: {year} - {num_classes} classes")


@plot_app.command()
@execution_time
def most_discrepant(
    input_file: str = "classification_plots/integral_pvalues_data.json",
    output_dir: str = "classification_most_discrepant",
    skip_per_year: bool = True,
):
    """
    Plot the occupancy and p_integral of most discrepant classes.
    """
    from concurrent.futures import ProcessPoolExecutor, as_completed
    from rich.progress import track
    from rich.console import Console

    from integral_pvalues import integral_pvalues_summary, IntegralPValuePlotType

    os.system("rm -rf {}".format(output_dir))
    os.system("mkdir -p {}".format(output_dir))

    years = ["2016", "2017", "2018", "Run2"]
    if skip_per_year:
        years = ["Run2"]

    with ProcessPoolExecutor(max_workers=12) as executor:
        futures = []
        for y in years:
            futures.append(
                executor.submit(
                    integral_pvalues_summary,
                    input_file,
                    output_dir,
                    y,
                    20,
                    True,
                    True,
                    True,
                    IntegralPValuePlotType.MostDiscrepant,
                )
            )
            futures.append(
                executor.submit(
                    integral_pvalues_summary,
                    input_file,
                    output_dir,
                    y,
                    40,
                    True,
                    True,
                    True,
                    IntegralPValuePlotType.MostDiscrepant,
                )
            )
            futures.append(
                executor.submit(
                    integral_pvalues_summary,
                    input_file,
                    output_dir,
                    y,
                    100,
                    True,
                    True,
                    True,
                    IntegralPValuePlotType.MostDiscrepant,
                )
            )

        console = Console()
        for future in track(
            as_completed(futures),
            total=len(futures),
            description="Most discrepant scenarios...",
            console=console,
        ):
            year, num_classes = future.result()
            console.print(f"Done: {year} - {num_classes} classes")


@plot_app.command()
@execution_time
def summary(
    distribution: Optional[DistributionType] = None,
    class_type: ClassType = ClassType.All,
    input_dir: str = "scan_results",
    output_dir: str = "scan_summary_plots",
    num_cpus: int = 128,
    expected_n_rounds: int = 10_000,
):
    from p_tilde import plot_summary

    os.system("rm -rf {}".format(output_dir))
    os.system("mkdir -p {}".format(output_dir))

    if distribution:
        plot_summary(
            distribution=distribution,
            input_dir=input_dir,
            output_dir=output_dir,
            num_cpus=num_cpus,
            class_type=class_type,
            expected_n_rounds=expected_n_rounds,
        )
    else:
        for distribution in DistributionType:
            plot_summary(
                distribution=distribution,
                input_dir=input_dir,
                output_dir=output_dir,
                num_cpus=num_cpus,
                class_type=class_type,
                expected_n_rounds=expected_n_rounds,
            )


@plot_app.command()
@execution_time
def web_summary():
    """
    Make web summary of file contents.
    """
    from web_summary import make_web_summary

    make_web_summary("./classification_most_occupied")
    make_web_summary("./classification_most_discrepant")
    make_web_summary("./classification_plots")
    make_web_summary("./validation_plots")
    make_web_summary("./scan_summary_plots")


@plot_app.command()
@execution_time
def render_latex(
    input_dir: str = "classification_plots",
    output_dir: str = "classification_plots",
    render: bool = False,
):
    from latex_summary import render_latex

    render_latex(input_dir, output_dir, render)


############################################################################
############################################################################
# Scanner
############################################################################
############################################################################
scan_app = typer.Typer(
    help="Start and monitor Region of Interest scans.",
    pretty_exceptions_show_locals=False,
)


class DistributionsType(str, Enum):
    InvariantMass = "invariant_mass"
    SumPt = "sum_pt"
    MET = "met"


class ScanTarget(str, Enum):
    Local = "local"
    CRAB = "crab"
    CMSSW = "cmssw"


@scan_app.command()
@execution_time
def prepare_cmssw_env():
    """
    Will configure a CMSSW area for the scanner.
    """

    from cmssw_scan import prepare_cmssw_env

    prepare_cmssw_env()


@scan_app.command()
@execution_time
def start(
    distribution: Union[DistributionsType, None] = None,
    class_type: ClassType = ClassType.All,
    input_dir: str = "classification_distributions",
    filters: list[str] = ["*"],
    output_dir: str = "scan_results",
    num_cpus: int = 128,
    do_clean: bool = False,
    n_rounds: int = 10_000,
    split_size: int = 5_000,
    target: ScanTarget = ScanTarget.CRAB,
):
    """
    Launch RoIScan.
    """

    if split_size < 1:
        print("ERROR: Could not start scan. split_size should be > 0.", file=sys.stderr)
        sys.exit(1)

    if n_rounds < 1:
        print("ERROR: Could not start scan. n_rounds should be > 0.", file=sys.stderr)
        sys.exit(1)

    if n_rounds % split_size != 0:
        print("ERROR: n-rounds should be divisible by split-size.", file=sys.stderr)
        sys.exit(1)

    from scan import start_scan, start_crab_scan

    if target == ScanTarget.Local:
        if distribution:
            start_scan(
                input_dir,
                filters,
                distribution.value,
                class_type,
                output_dir,
                num_cpus,
                do_clean,
                n_rounds,
                split_size,
            )
        else:
            start_scan(
                input_dir,
                filters,
                DistributionsType.InvariantMass.value,
                class_type,
                output_dir,
                num_cpus,
                do_clean,
                n_rounds,
                split_size,
            )
            start_scan(
                input_dir,
                filters,
                DistributionsType.SumPt.value,
                class_type,
                output_dir,
                num_cpus,
                do_clean,
                n_rounds,
                split_size,
            )
            start_scan(
                input_dir,
                filters,
                DistributionsType.MET.value,
                class_type,
                output_dir,
                num_cpus,
                do_clean,
                n_rounds,
                split_size,
            )

    if target == ScanTarget.CRAB:
        start_crab_scan(
            input_dir,
            filters,
            output_dir,
            num_cpus,
            do_clean,
            n_rounds,
            split_size,
        )


@scan_app.command()
@execution_time
def monitor(long: bool = False):
    """
    Monitor Scanner task on CRAB.
    """

    if long:
        os.system(
            r'cmssw-el9 --cleanenv --command-to-run "cd CMSSW_14_0_7/src && cmsenv && cd ../.. && crab status --long"'
        )
    else:
        os.system(
            r'cmssw-el9 --cleanenv --command-to-run "cd CMSSW_14_0_7/src && cmsenv && cd ../.. && ./crab_worker.sh"'
        )


@scan_app.command()
@execution_time
def kill():
    """
    Kill Scanner task on CRAB.
    """

    os.system(
        r'cmssw-el9 --cleanenv --command-to-run "cd CMSSW_14_0_7/src && cmsenv && cd ../.. && crab kill -d crab_MUSIC_CLASSIFICATION"'
    )


@scan_app.command()
@execution_time
def get_output(skip_download: bool = False):
    """
    Get outputs of CRAB Scanner task.
    """

    from scan import get_output

    get_output(skip_download)


@scan_app.command()
@execution_time
def clean():
    """
    Clear Scanner task on CRAB.
    """

    exec_command(
        r"rm -rf __pycache__ crab.log crab_MUSIC_CLASSIFICATION crab_worker.sh pset.py crab_sub.py music.sh scan_results scan_results.tar"
    )


@scan_app.command()
@execution_time
def scan_remaining(
    results_dir: str = "scan_results",
    input_dir: str = "classification_distributions",
    n_rounds: int = 10_000,
    split_size: int = 1_000,
):
    """
    Scan unfinished distributions.
    """

    from scan import scan_remaining

    scan_remaining(
        results_dir,
        input_dir,
        n_rounds,
        split_size,
    )


############################################################################
############################################################################
# Main
############################################################################
############################################################################
app = typer.Typer(pretty_exceptions_show_locals=False)
app.add_typer(classification_app, name="classification")
app.add_typer(plot_app, name="plot")
app.add_typer(scan_app, name="scan")

if __name__ == "__main__":
    app()
